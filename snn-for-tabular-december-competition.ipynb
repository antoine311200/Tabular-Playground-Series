{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-08T19:14:03.547523Z","iopub.execute_input":"2021-12-08T19:14:03.54844Z","iopub.status.idle":"2021-12-08T19:14:03.596779Z","shell.execute_reply.started":"2021-12-08T19:14:03.548265Z","shell.execute_reply":"2021-12-08T19:14:03.595497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom scipy.stats import mode\n\nfrom sklearn.preprocessing import LabelEncoder, RobustScaler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.utils import class_weight\n\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler, TomekLinks\n\nfrom xgboost import XGBClassifier, DMatrix, train\n\nimport lightgbm as lgb\n\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-12-08T19:14:03.599307Z","iopub.execute_input":"2021-12-08T19:14:03.600386Z","iopub.status.idle":"2021-12-08T19:14:07.958259Z","shell.execute_reply.started":"2021-12-08T19:14:03.600336Z","shell.execute_reply":"2021-12-08T19:14:07.957145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-12-08T19:14:07.960303Z","iopub.execute_input":"2021-12-08T19:14:07.960715Z","iopub.status.idle":"2021-12-08T19:14:07.979241Z","shell.execute_reply.started":"2021-12-08T19:14:07.960667Z","shell.execute_reply":"2021-12-08T19:14:07.977972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_dataframe = pd.read_csv('../input/tabular-playground-series-dec-2021/train.csv')\ntest_dataframe = pd.read_csv('../input/tabular-playground-series-dec-2021/test.csv')\n\ntrain_dataframe.describe()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-08T19:14:07.983569Z","iopub.execute_input":"2021-12-08T19:14:07.98418Z","iopub.status.idle":"2021-12-08T19:14:39.561998Z","shell.execute_reply.started":"2021-12-08T19:14:07.984132Z","shell.execute_reply":"2021-12-08T19:14:39.560794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_engineer(dataframe):\n    \n    cols = [\"Soil_Type7\", \"Soil_Type15\"]\n\n    dataframe.drop(cols, axis=1, inplace=True)\n\n    dataframe[\"Aspect\"][dataframe[\"Aspect\"] < 0] += 360\n    dataframe[\"Aspect\"][dataframe[\"Aspect\"] > 359] -= 360\n\n    # Manhhattan Distance\n    dataframe[\"Manhhattan_Distance\"] = np.abs(dataframe[\"Horizontal_Distance_To_Hydrology\"])+np.abs(dataframe[\"Vertical_Distance_To_Hydrology\"])\n\n    # Euclidian Distance\n    dataframe[\"Euclidian_Distance\"] = (dataframe[\"Horizontal_Distance_To_Hydrology\"]**2 + dataframe[\"Vertical_Distance_To_Hydrology\"]**2)**0.5\n\n    # Combine Soil features\n    soil_features = [x for x in dataframe.columns if x.startswith(\"Soil_Type\")]\n    dataframe[\"Soil_Type_Count\"] = dataframe[soil_features].sum(axis=1)\n\n    # Combine Wilderness features\n    wilderness_features = [x for x in dataframe.columns if x.startswith(\"Wilderness_Area\")]\n    dataframe[\"Wilderness_Area_Count\"] = dataframe[wilderness_features].sum(axis=1)\n\n    dataframe.loc[dataframe[\"Hillshade_9am\"] < 0, \"Hillshade_9am\"] = 0\n    dataframe.loc[dataframe[\"Hillshade_Noon\"] < 0, \"Hillshade_Noon\"] = 0\n    dataframe.loc[dataframe[\"Hillshade_3pm\"] < 0, \"Hillshade_3pm\"] = 0\n\n    dataframe.loc[dataframe[\"Hillshade_9am\"] > 255, \"Hillshade_9am\"] = 255\n    dataframe.loc[dataframe[\"Hillshade_Noon\"] > 255, \"Hillshade_Noon\"] = 255\n    dataframe.loc[dataframe[\"Hillshade_3pm\"] > 255, \"Hillshade_3pm\"] = 255\n\n    dataframe['Hillshade'] = dataframe['Hillshade_9am'] + dataframe['Hillshade_Noon'] + dataframe['Hillshade_3pm']\n\n    dataframe['Hydro_Elevation'] = dataframe['Elevation'] - dataframe['Vertical_Distance_To_Hydrology']\n\n    dataframe['Binned_Elevation'] = [np.floor(v/50.0) for v in dataframe['Elevation']]\n\n    dataframe['Horizontal_Distance_To_Roadways'][dataframe['Horizontal_Distance_To_Roadways'] < 0] = 0\n    dataframe['Horizontal_Distance_To_Roadways_Log'] = [np.log(v+1) for v in dataframe['Horizontal_Distance_To_Roadways']]\n\n    dataframe['Horizontal_Distance_To_Fire_Points'][dataframe['Horizontal_Distance_To_Fire_Points'] < 0] = 0\n    dataframe['Horizontal_Distance_To_Fire_Points_Log'] = [np.log(v+1) for v in dataframe['Horizontal_Distance_To_Fire_Points']]\n\n    return dataframe","metadata":{"execution":{"iopub.status.busy":"2021-12-08T19:14:39.564046Z","iopub.execute_input":"2021-12-08T19:14:39.564767Z","iopub.status.idle":"2021-12-08T19:14:39.582722Z","shell.execute_reply.started":"2021-12-08T19:14:39.564719Z","shell.execute_reply":"2021-12-08T19:14:39.581384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataframe = feature_engineer(train_dataframe)\ntest_dataframe = feature_engineer(test_dataframe)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T19:14:39.586092Z","iopub.execute_input":"2021-12-08T19:14:39.586515Z","iopub.status.idle":"2021-12-08T19:15:23.182079Z","shell.execute_reply.started":"2021-12-08T19:14:39.586468Z","shell.execute_reply":"2021-12-08T19:15:23.180967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncols = [\n    \"Elevation\",\n    \"Aspect\",\n    \"Manhhattan_Distance\",\n    \"Euclidian_Distance\",\n    \"Soil_Type_Count\",\n    \"Wilderness_Area_Count\",\n    \"Slope\",\n    \"Horizontal_Distance_To_Hydrology\",\n    \"Vertical_Distance_To_Hydrology\",\n    \"Horizontal_Distance_To_Roadways\",\n    \"Horizontal_Distance_To_Roadways_Log\",\n    \"Hillshade_9am\",\n    \"Hillshade_Noon\",\n    \"Hillshade_3pm\",\n    \"Hillshade\",\n    \"Horizontal_Distance_To_Fire_Points\",\n    \"Horizontal_Distance_To_Fire_Points_Log\",\n    \"Binned_Elevation\",\n    \"Hydro_Elevation\"\n]\n\nscaler = RobustScaler()\n\ntrain_dataframe[cols] = scaler.fit_transform(train_dataframe[cols])\ntest_dataframe[cols] = scaler.transform(test_dataframe[cols])","metadata":{"execution":{"iopub.status.busy":"2021-12-08T19:15:23.183917Z","iopub.execute_input":"2021-12-08T19:15:23.184253Z","iopub.status.idle":"2021-12-08T19:15:42.778756Z","shell.execute_reply.started":"2021-12-08T19:15:23.184208Z","shell.execute_reply":"2021-12-08T19:15:42.777605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\ntrain_dataframe[\"Cover_Type\"] = encoder.fit_transform(train_dataframe[\"Cover_Type\"])","metadata":{"execution":{"iopub.status.busy":"2021-12-08T19:15:42.780586Z","iopub.execute_input":"2021-12-08T19:15:42.78108Z","iopub.status.idle":"2021-12-08T19:15:43.100289Z","shell.execute_reply.started":"2021-12-08T19:15:42.781019Z","shell.execute_reply":"2021-12-08T19:15:43.098952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataframe = reduce_mem_usage(train_dataframe)\ntest_dataframe = reduce_mem_usage(test_dataframe)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T19:15:43.101979Z","iopub.execute_input":"2021-12-08T19:15:43.102961Z","iopub.status.idle":"2021-12-08T19:15:59.559557Z","shell.execute_reply.started":"2021-12-08T19:15:43.102909Z","shell.execute_reply":"2021-12-08T19:15:59.558345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataframe.head()\ntrain_dataframe.describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-08T19:15:59.563973Z","iopub.execute_input":"2021-12-08T19:15:59.565105Z","iopub.status.idle":"2021-12-08T19:16:15.776791Z","shell.execute_reply.started":"2021-12-08T19:15:59.56505Z","shell.execute_reply":"2021-12-08T19:16:15.775533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_dataframe.drop(\"Cover_Type\", axis=1).values\ny = train_dataframe[\"Cover_Type\"].values\n\n\n# x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.15)\n\nclasses_number = len(train_dataframe[\"Cover_Type\"].unique())","metadata":{"execution":{"iopub.status.busy":"2021-12-08T19:16:15.786481Z","iopub.execute_input":"2021-12-08T19:16:15.787047Z","iopub.status.idle":"2021-12-08T19:16:16.780324Z","shell.execute_reply.started":"2021-12-08T19:16:15.786995Z","shell.execute_reply":"2021-12-08T19:16:16.779293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import layers\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom keras import Sequential\n\nearly_stopping = EarlyStopping(\n    patience=10,\n    min_delta=0,\n    monitor='val_acc',\n    mode='max',\n    restore_best_weights=True,       \n    baseline=None,\n    verbose=2,\n)\n\nlearning_rate_reduction = ReduceLROnPlateau(\n        patience=5,\n        factor=0.5,\n        monitor='val_loss', \n        mode='min',\n        verbose=2,\n)\n\n\ncheckpoint = ModelCheckpoint(\n    \"snn_model.hdf5\",\n    monitor='loss',\n    verbose=1,\n    save_best_only=True,\n    mode='auto',\n    save_freq='epoch'\n)\n\ncallbacks = [early_stopping, learning_rate_reduction, checkpoint]\n\nACTIVATION = \"swish\"\nDROPOUT = 0.1\n\ndef build_model():\n    model = Sequential([\n        layers.BatchNormalization(input_shape = [X.shape[-1]], name='input'),\n        layers.Dense(300, kernel_initializer=\"lecun_normal\", activation=ACTIVATION),\n        layers.Dropout(rate = DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(200, kernel_initializer=\"lecun_normal\", activation=ACTIVATION),\n        layers.Dropout(rate = DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(100, kernel_initializer=\"lecun_normal\", activation=ACTIVATION),\n        layers.Dropout(rate = DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(50, kernel_initializer=\"lecun_normal\", activation=ACTIVATION),\n        layers.Dropout(rate = DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(classes_number, activation = 'softmax'),\n    ])\n\n    model.compile(\n        optimizer= 'adam',\n        loss='sparse_categorical_crossentropy',\n        metrics=['acc'],\n    )\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-08T19:48:55.181231Z","iopub.execute_input":"2021-12-08T19:48:55.181561Z","iopub.status.idle":"2021-12-08T19:48:55.200083Z","shell.execute_reply.started":"2021-12-08T19:48:55.181527Z","shell.execute_reply":"2021-12-08T19:48:55.198674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 200\nBATCH_SIZE = 4096\nFOLDS = 20\n\ntest_predictions = np.zeros((1, 1))\nscores = []\n\nkfolds = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n\nfor fold, (train_idx, val_idx) in enumerate(kfolds.split(X, y)):\n    x_train, x_val = X[train_idx], X[val_idx]\n    y_train, y_val = y[train_idx], y[val_idx]\n\n    model = build_model()\n    model.fit(\n        x_train,\n        y_train,\n        validation_data=(x_val, y_val),\n        epochs=EPOCHS,\n        batch_size=BATCH_SIZE,\n        callbacks=callbacks,\n        verbose=1\n    )\n\n    y_pred = np.argmax(model.predict(x_val), axis=1)\n    score = accuracy_score(y_val, y_pred)\n    scores.append(score)\n\n    test_predictions = test_predictions + model.predict(test_dataframe)\n    print(f\"Fold n°{fold} -> Accuracy: {score}\")\n\nprint()\nprint(f\"Mean Accuracy: {np.mean(scores)}\")","metadata":{"execution":{"iopub.status.busy":"2021-12-08T19:48:55.741508Z","iopub.execute_input":"2021-12-08T19:48:55.742378Z","iopub.status.idle":"2021-12-08T21:59:21.305792Z","shell.execute_reply.started":"2021-12-08T19:48:55.742339Z","shell.execute_reply":"2021-12-08T21:59:21.303353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# history = model.fit(\n#     x_train, y_train,\n#     validation_data = (x_val, y_val),\n#     batch_size      = BATCH_SIZE, \n#     epochs          = EPOCHS,\n#     callbacks       = [early_stopping, learning_rate_reduction, checkpoint],\n#     shuffle         = True,\n#     verbose         = 1,\n# )\n\npd.DataFrame(test_predictions).to_csv(\"test_predictions.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T22:04:57.653286Z","iopub.execute_input":"2021-12-08T22:04:57.65366Z","iopub.status.idle":"2021-12-08T22:05:14.497978Z","shell.execute_reply.started":"2021-12-08T22:04:57.653598Z","shell.execute_reply":"2021-12-08T22:05:14.496856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntest_predictions = pd.read_csv(\"test_predictions.csv\").to_numpy()\n\ntest_predictions = encoder.inverse_transform(np.argmax(test_predictions, axis=1))\n","metadata":{"execution":{"iopub.status.busy":"2021-12-08T22:21:34.824017Z","iopub.execute_input":"2021-12-08T22:21:34.824941Z","iopub.status.idle":"2021-12-08T22:21:36.223307Z","shell.execute_reply.started":"2021-12-08T22:21:34.824902Z","shell.execute_reply":"2021-12-08T22:21:36.221639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsubmission_df = pd.read_csv(\"../input/tabular-playground-series-dec-2021/sample_submission.csv\")\n\ntest_ids = test_dataframe.Id.values.tolist()\n\nsubmission_df = pd.DataFrame(list(zip(test_ids, test_predictions)), columns=[\"Id\", \"Cover_Type\"])\n\nsubmission_df.columns = [\"Id\", \"Cover_Type\"]\nsubmission_df.to_csv(\"submission.csv\", index=False)\nsubmission_df.head(20)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T22:21:47.133503Z","iopub.execute_input":"2021-12-08T22:21:47.134072Z","iopub.status.idle":"2021-12-08T22:21:50.706028Z","shell.execute_reply.started":"2021-12-08T22:21:47.134035Z","shell.execute_reply":"2021-12-08T22:21:50.704969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(submission_df.describe())","metadata":{"execution":{"iopub.status.busy":"2021-12-08T22:08:59.172381Z","iopub.execute_input":"2021-12-08T22:08:59.172969Z","iopub.status.idle":"2021-12-08T22:08:59.259575Z","shell.execute_reply.started":"2021-12-08T22:08:59.172918Z","shell.execute_reply":"2021-12-08T22:08:59.255524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}